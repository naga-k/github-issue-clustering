{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783f8dd4",
   "metadata": {},
   "source": [
    "# Issue Clustering\n",
    "\n",
    "This notebook clusters issue/feedback items from a CSV, evaluates against provided labels, and compares three strategies:\n",
    "\n",
    "- Agglomerative clustering (cosine, threshold-based, batch)\n",
    "- Vector-style incremental assignment (simulates vector DB neighbor-join)\n",
    "- Centroid-style incremental assignment\n",
    "\n",
    "It uses Gemini embeddings by default (set `GOOGLE_API_KEY`) or any SentenceTransformer model if you change `model_name`. Ensure `issues_raw.csv` exists with columns `title`, `body`, and optional `label`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d849d01",
   "metadata": {},
   "source": [
    "Add a `.env` file with `GOOGLE_API_KEY=your_key` if you want Gemini embeddings. To run offline, switch `model_name` to a SentenceTransformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -U sentence-transformers scikit-learn numpy requests python-dotenv pandas packaging google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19e95b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sklearn\n",
    "from packaging import version\n",
    "from google import genai\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai_client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\")) if os.getenv(\"GOOGLE_API_KEY\") else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d8dd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_issues(\n",
    "    issues,                      # list[dict] with keys: title, body (body optional)\n",
    "    model_name=\"gemini-embedding-001\",\n",
    "    sim_threshold=0.70,          # higher => fewer, tighter clusters\n",
    "    min_cluster_size=2,\n",
    "    truncate_body_chars=1500,    # prevent very long bodies from dominating\n",
    "    label_singletons_as_minus_one=True,\n",
    "):\n",
    "    \"\"\"Cluster issue dicts by semantic similarity.\n",
    "\n",
    "    Embeddings source is chosen by model_name:\n",
    "    - If model_name starts with \"gemini\" (e.g., \"gemini-embedding-001\"), use Gemini via GOOGLE_API_KEY.\n",
    "    - Otherwise, use SentenceTransformer(model_name).\n",
    "\n",
    "    Returns both raw labels from sklearn and display labels (optionally -1 for singletons).\n",
    "    \"\"\"\n",
    "    def _to_text(val):\n",
    "        if val is None:\n",
    "            return \"\"\n",
    "        if isinstance(val, str):\n",
    "            return val\n",
    "        if isinstance(val, float):\n",
    "            return \"\" if np.isnan(val) else str(val)\n",
    "        return str(val)\n",
    "\n",
    "    texts = []\n",
    "    for it in issues:\n",
    "        title = _to_text(it.get(\"title\")).strip()\n",
    "        body = _to_text(it.get(\"body\")).strip()\n",
    "        if truncate_body_chars:\n",
    "            body = body[:truncate_body_chars]\n",
    "        text = f\"{title}\\n\\n{body}\".strip()\n",
    "        if not text:\n",
    "            text = \"[empty]\"\n",
    "        texts.append(text)\n",
    "\n",
    "    if not texts:\n",
    "        return {\n",
    "            \"labels\": np.array([], dtype=int),\n",
    "            \"display_labels\": np.array([], dtype=int),\n",
    "            \"clusters\": {},\n",
    "            \"singletons\": [],\n",
    "            \"texts\": texts,\n",
    "        }\n",
    "\n",
    "    if len(texts) == 1:\n",
    "        labels = np.array([0], dtype=int)\n",
    "        display_labels = np.array([-1], dtype=int) if label_singletons_as_minus_one else labels.copy()\n",
    "        clusters = {0: [0]} if min_cluster_size <= 1 else {}\n",
    "        singletons = [0]\n",
    "        return {\n",
    "            \"labels\": labels,\n",
    "            \"display_labels\": display_labels,\n",
    "            \"clusters\": clusters,\n",
    "            \"singletons\": singletons,\n",
    "            \"texts\": texts,\n",
    "        }\n",
    "\n",
    "    if model_name.lower().startswith(\"gemini\"):\n",
    "        if genai_client is None:\n",
    "            raise RuntimeError(\"GOOGLE_API_KEY not set; populate .env or environment\")\n",
    "        resp = genai_client.models.embed_content(\n",
    "            model=model_name,\n",
    "            contents=texts,\n",
    "            config={\"output_dimensionality\": 768},\n",
    "        )\n",
    "        emb = np.asarray([e.values for e in resp.embeddings], dtype=np.float32)\n",
    "        print(\"Using Gemini Text Embedding\")\n",
    "    else:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        emb = model.encode(\n",
    "            texts,\n",
    "            batch_size=32,\n",
    "            show_progress_bar=True,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        emb = np.asarray(emb, dtype=np.float32)\n",
    "        print(\"Using HF Sentence Transformer Embedding\")\n",
    "\n",
    "    norms = np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    emb = emb / norms\n",
    "\n",
    "    dist_threshold = 1.0 - float(sim_threshold)\n",
    "\n",
    "    kwargs = dict(n_clusters=None, linkage=\"average\", distance_threshold=dist_threshold)\n",
    "    if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "        kwargs[\"metric\"] = \"cosine\"\n",
    "    else:\n",
    "        kwargs[\"affinity\"] = \"cosine\"\n",
    "\n",
    "    cl = AgglomerativeClustering(**kwargs)\n",
    "    labels = cl.fit_predict(emb)\n",
    "\n",
    "    clusters = {}\n",
    "    for i, lab in enumerate(labels):\n",
    "        clusters.setdefault(int(lab), []).append(i)\n",
    "\n",
    "    kept = {k: v for k, v in clusters.items() if len(v) >= min_cluster_size}\n",
    "    singletons = [v[0] for k, v in clusters.items() if len(v) == 1]\n",
    "    kept = dict(sorted(kept.items(), key=lambda kv: len(kv[1]), reverse=True))\n",
    "\n",
    "    display_labels = labels.copy()\n",
    "    if label_singletons_as_minus_one:\n",
    "        for i in singletons:\n",
    "            display_labels[i] = -1\n",
    "\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"display_labels\": display_labels,\n",
    "        \"clusters\": kept,\n",
    "        \"singletons\": singletons,\n",
    "        \"texts\": texts,\n",
    "    }\n",
    "\n",
    "def print_clusters(result, issues, max_items_per_cluster=8):\n",
    "    for cid, idxs in result[\"clusters\"].items():\n",
    "        print(f\"\\n=== Cluster {cid}  (n={len(idxs)}) ===\")\n",
    "        for j in idxs[:max_items_per_cluster]:\n",
    "            t = (issues[j].get(\"title\") or \"\").strip().replace(\"\\n\", \" \")\n",
    "            print(f\"- [{j:02d}] {t[:140]}\")\n",
    "    if result[\"singletons\"]:\n",
    "        print(f\"\\nSingletons (n={len(result['singletons'])}): {result['singletons']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9f654",
   "metadata": {},
   "source": [
    "## Tabular cluster view helper\n",
    "Creates a DataFrame with cluster id, cluster size, issue index, title, and body so you can sort/filter in the notebook UI. Use the raw issues CSV helper if you want to label without clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e47a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_as_dataframe(result, issues):\n",
    "    \"\"\"Return a DataFrame with raw/display labels, cluster size, issue index, title, body.\"\"\"\n",
    "    rows = []\n",
    "    cluster_sizes = {cid: len(idxs) for cid, idxs in result.get(\"clusters\", {}).items()}\n",
    "    display_labels = result.get(\"display_labels\", result.get(\"labels\", []))\n",
    "    labels = result.get(\"labels\", [])\n",
    "\n",
    "    def _to_text(val):\n",
    "        if val is None:\n",
    "            return \"\"\n",
    "        if isinstance(val, str):\n",
    "            return val\n",
    "        if isinstance(val, float):\n",
    "            return \"\" if np.isnan(val) else str(val)\n",
    "        return str(val)\n",
    "\n",
    "    for j, issue in enumerate(issues):\n",
    "        raw_lab = int(labels[j]) if len(labels) > j else None\n",
    "        disp_lab = int(display_labels[j]) if len(display_labels) > j else None\n",
    "        cluster_size = cluster_sizes.get(raw_lab, 1) if raw_lab is not None else 1\n",
    "        rows.append({\n",
    "            \"cluster_raw\": raw_lab,\n",
    "            \"cluster_display\": disp_lab,\n",
    "            \"is_singleton\": disp_lab == -1,\n",
    "            \"cluster_size\": cluster_size,\n",
    "            \"idx\": j,\n",
    "            \"title\": _to_text(issue.get(\"title\")),\n",
    "            \"body\": _to_text(issue.get(\"body\")),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values([\"is_singleton\", \"cluster_size\", \"cluster_display\", \"idx\"], ascending=[True, False, True, True]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_issues_csv(issues, path=\"issues_raw.csv\"):\n",
    "    \"\"\"Save the raw (unclustered) issues to CSV for manual labeling.\"\"\"\n",
    "    def _to_text(val):\n",
    "        if val is None:\n",
    "            return \"\"\n",
    "        if isinstance(val, str):\n",
    "            return val\n",
    "        if isinstance(val, float):\n",
    "            return \"\" if np.isnan(val) else str(val)\n",
    "        return str(val)\n",
    "\n",
    "    rows = []\n",
    "    for idx, it in enumerate(issues):\n",
    "        rows.append({\n",
    "            \"idx\": idx,\n",
    "            \"title\": _to_text(it.get(\"title\")).strip(),\n",
    "            \"body\": _to_text(it.get(\"body\")).strip(),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Wrote {len(df)} issues to {path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce218fe7",
   "metadata": {},
   "source": [
    "## Example: cluster from CSV\n",
    "Load labeled issues from `issues_raw.csv`, cluster them, and evaluate against the provided labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61245471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load issues from CSV, cluster, and evaluate\n",
    "csv_path = \"issues_raw.csv\"\n",
    "\n",
    "df_src = pd.read_csv(csv_path)\n",
    "issues = df_src[[\"title\", \"body\"]].to_dict(\"records\")\n",
    "true_labels = df_src[\"label\"].tolist() if \"label\" in df_src.columns else None\n",
    "\n",
    "res = cluster_issues(issues, sim_threshold=0.72, min_cluster_size=2, label_singletons_as_minus_one=False)\n",
    "print_clusters(res, issues)\n",
    "\n",
    "df_clusters = clusters_as_dataframe(res, issues)\n",
    "display(df_clusters.head(200))\n",
    "\n",
    "if true_labels is not None:\n",
    "    # Evaluate clustering vs. provided labels\n",
    "    from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_completeness_v_measure\n",
    "\n",
    "    # Map string labels to ints for metrics\n",
    "    true_enc, _ = pd.factorize(true_labels)\n",
    "    pred_enc, _ = pd.factorize(res[\"display_labels\"])\n",
    "\n",
    "    ari = adjusted_rand_score(true_enc, pred_enc)\n",
    "    ami = adjusted_mutual_info_score(true_enc, pred_enc, average_method=\"arithmetic\")\n",
    "    h, c, v = homogeneity_completeness_v_measure(true_enc, pred_enc)\n",
    "\n",
    "    print(f\"ARI: {ari:.3f}\")\n",
    "    print(f\"AMI: {ami:.3f}\")\n",
    "    print(f\"Homogeneity: {h:.3f}  Completeness: {c:.3f}  V-Measure: {v:.3f}\")\n",
    "else:\n",
    "    print(\"No labels column found; skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "620e75a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Gemini Text Embedding\n",
      "Agglomerative -> ARI: 0.879 | AMI: 0.873 | H: 0.979 C: 0.956 V: 0.967\n",
      "Vector-like -> ARI: 0.865 | AMI: 0.836 | H: 0.977 C: 0.942 V: 0.959\n",
      "Centroid-like -> ARI: 0.543 | AMI: 0.681 | H: 0.845 C: 0.949 V: 0.894\n"
     ]
    }
   ],
   "source": [
    "# Compare agglomerative vs vector-like vs centroid-like on CSV labels\n",
    "import math\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_completeness_v_measure\n",
    "\n",
    "def _prep_texts(issues, truncate_body_chars=1500):\n",
    "    def _to_text(val):\n",
    "        if val is None:\n",
    "            return \"\"\n",
    "        if isinstance(val, str):\n",
    "            return val\n",
    "        if isinstance(val, float):\n",
    "            return \"\" if np.isnan(val) else str(val)\n",
    "        return str(val)\n",
    "    texts = []\n",
    "    for it in issues:\n",
    "        title = _to_text(it.get(\"title\")).strip()\n",
    "        body = _to_text(it.get(\"body\")).strip()\n",
    "        if truncate_body_chars:\n",
    "            body = body[:truncate_body_chars]\n",
    "        txt = f\"{title}\\n\\n{body}\".strip()\n",
    "        texts.append(txt or \"[empty]\")\n",
    "    return texts\n",
    "\n",
    "def embed_texts(texts, model_name=\"gemini-embedding-001\"):\n",
    "    if model_name.lower().startswith(\"gemini\"):\n",
    "        if genai_client is None:\n",
    "            raise RuntimeError(\"GOOGLE_API_KEY not set; populate .env or environment\")\n",
    "        resp = genai_client.models.embed_content(\n",
    "            model=model_name,\n",
    "            contents=texts,\n",
    "            config={\"output_dimensionality\": 768},\n",
    "        )\n",
    "        emb = np.asarray([e.values for e in resp.embeddings], dtype=np.float32)\n",
    "    else:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        emb = model.encode(\n",
    "            texts,\n",
    "            batch_size=32,\n",
    "            show_progress_bar=True,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        emb = np.asarray(emb, dtype=np.float32)\n",
    "    norms = np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    return emb / norms\n",
    "\n",
    "def cosine(a, b):\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "def vector_like_cluster(embeddings, threshold=0.72):\n",
    "    labels = []\n",
    "    next_cluster = 0\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        sims = [cosine(emb, embeddings[j]) for j in range(i)]\n",
    "        similars = [j for j, s in enumerate(sims) if s >= threshold]\n",
    "        if similars:\n",
    "            labels.append(labels[similars[0]])\n",
    "        else:\n",
    "            labels.append(next_cluster)\n",
    "            next_cluster += 1\n",
    "    return np.array(labels, dtype=int)\n",
    "\n",
    "def centroid_cluster(embeddings, threshold=0.65):\n",
    "    centroids = []\n",
    "    labels = []\n",
    "    for emb in embeddings:\n",
    "        if not centroids:\n",
    "            labels.append(0)\n",
    "            centroids.append(emb.copy())\n",
    "            continue\n",
    "        sims = [cosine(emb, c) for c in centroids]\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        if sims[best_idx] >= threshold:\n",
    "            k = best_idx\n",
    "            count_k = labels.count(k)\n",
    "            centroids[k] = (centroids[k] * count_k + emb) / (count_k + 1)\n",
    "            labels.append(k)\n",
    "        else:\n",
    "            labels.append(len(centroids))\n",
    "            centroids.append(emb.copy())\n",
    "    return np.array(labels, dtype=int)\n",
    "\n",
    "def evaluate(true_labels, pred_labels, name):\n",
    "    true_enc, _ = pd.factorize(pd.Series(true_labels))\n",
    "    pred_enc, _ = pd.factorize(pd.Series(pred_labels))\n",
    "    ari = adjusted_rand_score(true_enc, pred_enc)\n",
    "    ami = adjusted_mutual_info_score(true_enc, pred_enc, average_method=\"arithmetic\")\n",
    "    h, c, v = homogeneity_completeness_v_measure(true_enc, pred_enc)\n",
    "    print(f\"{name} -> ARI: {ari:.3f} | AMI: {ami:.3f} | H: {h:.3f} C: {c:.3f} V: {v:.3f}\")\n",
    "\n",
    "# Load data\n",
    "csv_path = \"issues_raw.csv\"\n",
    "df_src = pd.read_csv(csv_path)\n",
    "issues = df_src[[\"title\", \"body\"]].to_dict(\"records\")\n",
    "true_labels = df_src[\"label\"].tolist() if \"label\" in df_src.columns else None\n",
    "\n",
    "texts = _prep_texts(issues)\n",
    "emb = embed_texts(texts, model_name=\"gemini-embedding-001\")\n",
    "\n",
    "# Agglomerative (existing)\n",
    "res_aggl = cluster_issues(issues, sim_threshold=0.72, min_cluster_size=2, label_singletons_as_minus_one=False)\n",
    "\n",
    "# Vector-style (incremental neighbor above threshold)\n",
    "vec_labels = vector_like_cluster(emb, threshold=0.72)\n",
    "\n",
    "# Centroid-style (assign to best centroid above threshold; else new)\n",
    "cent_labels = centroid_cluster(emb, threshold=0.65)\n",
    "\n",
    "if true_labels is not None:\n",
    "    evaluate(true_labels, res_aggl[\"display_labels\"], \"Agglomerative\")\n",
    "    evaluate(true_labels, vec_labels, \"Vector-like\")\n",
    "    evaluate(true_labels, cent_labels, \"Centroid-like\")\n",
    "else:\n",
    "    print(\"No labels column found; skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d555eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Gemini Text Embedding\n",
      "Agglomerative -> ARI: 0.879 | AMI: 0.873 | H: 0.979 C: 0.956 V: 0.967\n",
      "Vector-like -> ARI: 0.865 | AMI: 0.836 | H: 0.977 C: 0.942 V: 0.959\n",
      "Centroid-like -> ARI: 0.543 | AMI: 0.681 | H: 0.845 C: 0.949 V: 0.894\n"
     ]
    }
   ],
   "source": [
    "# Compare agglomerative vs vector-like vs centroid-like on CSV labels\n",
    "import math\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_completeness_v_measure\n",
    "\n",
    "def _prep_texts(issues, truncate_body_chars=1500):\n",
    "    def _to_text(val):\n",
    "        if val is None:\n",
    "            return \"\"\n",
    "        if isinstance(val, str):\n",
    "            return val\n",
    "        if isinstance(val, float):\n",
    "            return \"\" if np.isnan(val) else str(val)\n",
    "        return str(val)\n",
    "    texts = []\n",
    "    for it in issues:\n",
    "        title = _to_text(it.get(\"title\")).strip()\n",
    "        body = _to_text(it.get(\"body\")).strip()\n",
    "        if truncate_body_chars:\n",
    "            body = body[:truncate_body_chars]\n",
    "        txt = f\"{title}\\n\\n{body}\".strip()\n",
    "        texts.append(txt or \"[empty]\")\n",
    "    return texts\n",
    "\n",
    "def embed_texts(texts, model_name=\"gemini-embedding-001\"):\n",
    "    if model_name.lower().startswith(\"gemini\"):\n",
    "        if genai_client is None:\n",
    "            raise RuntimeError(\"GOOGLE_API_KEY not set; populate .env or environment\")\n",
    "        resp = genai_client.models.embed_content(\n",
    "            model=model_name,\n",
    "            contents=texts,\n",
    "            config={\"output_dimensionality\": 768},\n",
    "        )\n",
    "        emb = np.asarray([e.values for e in resp.embeddings], dtype=np.float32)\n",
    "    else:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        emb = model.encode(\n",
    "            texts,\n",
    "            batch_size=32,\n",
    "            show_progress_bar=True,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        emb = np.asarray(emb, dtype=np.float32)\n",
    "    norms = np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    return emb / norms\n",
    "\n",
    "def cosine(a, b):\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "def vector_like_cluster(embeddings, threshold=0.72):\n",
    "    labels = []\n",
    "    next_cluster = 0\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        sims = [cosine(emb, embeddings[j]) for j in range(i)]\n",
    "        similars = [j for j, s in enumerate(sims) if s >= threshold]\n",
    "        if similars:\n",
    "            labels.append(labels[similars[0]])\n",
    "        else:\n",
    "            labels.append(next_cluster)\n",
    "            next_cluster += 1\n",
    "    return np.array(labels, dtype=int)\n",
    "\n",
    "def centroid_cluster(embeddings, threshold=0.65):\n",
    "    centroids = []\n",
    "    labels = []\n",
    "    for emb in embeddings:\n",
    "        if not centroids:\n",
    "            labels.append(0)\n",
    "            centroids.append(emb.copy())\n",
    "            continue\n",
    "        sims = [cosine(emb, c) for c in centroids]\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        if sims[best_idx] >= threshold:\n",
    "            k = best_idx\n",
    "            count_k = labels.count(k)\n",
    "            centroids[k] = (centroids[k] * count_k + emb) / (count_k + 1)\n",
    "            labels.append(k)\n",
    "        else:\n",
    "            labels.append(len(centroids))\n",
    "            centroids.append(emb.copy())\n",
    "    return np.array(labels, dtype=int)\n",
    "\n",
    "def evaluate(true_labels, pred_labels, name):\n",
    "    true_enc, _ = pd.factorize(pd.Series(true_labels))\n",
    "    pred_enc, _ = pd.factorize(pd.Series(pred_labels))\n",
    "    ari = adjusted_rand_score(true_enc, pred_enc)\n",
    "    ami = adjusted_mutual_info_score(true_enc, pred_enc, average_method=\"arithmetic\")\n",
    "    h, c, v = homogeneity_completeness_v_measure(true_enc, pred_enc)\n",
    "    print(f\"{name} -> ARI: {ari:.3f} | AMI: {ami:.3f} | H: {h:.3f} C: {c:.3f} V: {v:.3f}\")\n",
    "\n",
    "# Load data\n",
    "csv_path = \"issues_raw.csv\"\n",
    "df_src = pd.read_csv(csv_path)\n",
    "issues = df_src[[\"title\", \"body\"]].to_dict(\"records\")\n",
    "true_labels = df_src[\"label\"].tolist() if \"label\" in df_src.columns else None\n",
    "\n",
    "texts = _prep_texts(issues)\n",
    "emb = embed_texts(texts, model_name=\"gemini-embedding-001\")\n",
    "\n",
    "# Agglomerative (existing)\n",
    "res_aggl = cluster_issues(issues, sim_threshold=0.72, min_cluster_size=2, label_singletons_as_minus_one=False)\n",
    "\n",
    "# Vector-style (incremental neighbor above threshold)\n",
    "vec_labels = vector_like_cluster(emb, threshold=0.72)\n",
    "\n",
    "# Centroid-style (assign to best centroid above threshold; else new)\n",
    "cent_labels = centroid_cluster(emb, threshold=0.65)\n",
    "\n",
    "if true_labels is not None:\n",
    "    evaluate(true_labels, res_aggl[\"display_labels\"], \"Agglomerative\")\n",
    "    evaluate(true_labels, vec_labels, \"Vector-like\")\n",
    "    evaluate(true_labels, cent_labels, \"Centroid-like\")\n",
    "else:\n",
    "    print(\"No labels column found; skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a0e5c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>ari</th>\n",
       "      <th>ami</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.878614</td>\n",
       "      <td>0.872694</td>\n",
       "      <td>0.979180</td>\n",
       "      <td>0.955741</td>\n",
       "      <td>0.967319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>0.865061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938823</td>\n",
       "      <td>0.968446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.861964</td>\n",
       "      <td>0.863814</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.944990</td>\n",
       "      <td>0.966776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.843574</td>\n",
       "      <td>0.840381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929737</td>\n",
       "      <td>0.963589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.819750</td>\n",
       "      <td>0.819377</td>\n",
       "      <td>0.946099</td>\n",
       "      <td>0.954265</td>\n",
       "      <td>0.950164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.554317</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.868050</td>\n",
       "      <td>0.950357</td>\n",
       "      <td>0.907341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.861964</td>\n",
       "      <td>0.863814</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.944990</td>\n",
       "      <td>0.966776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.849854</td>\n",
       "      <td>0.846509</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.963220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.715355</td>\n",
       "      <td>0.775847</td>\n",
       "      <td>0.917247</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>0.934730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.559797</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.860493</td>\n",
       "      <td>0.957934</td>\n",
       "      <td>0.906603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.447411</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.775449</td>\n",
       "      <td>0.939371</td>\n",
       "      <td>0.849575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.332870</td>\n",
       "      <td>0.484312</td>\n",
       "      <td>0.689798</td>\n",
       "      <td>0.910247</td>\n",
       "      <td>0.784836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.864654</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.941743</td>\n",
       "      <td>0.959205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.849854</td>\n",
       "      <td>0.846509</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.963220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.828405</td>\n",
       "      <td>0.808085</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.930745</td>\n",
       "      <td>0.953468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.824889</td>\n",
       "      <td>0.821949</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.929050</td>\n",
       "      <td>0.958365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.648380</td>\n",
       "      <td>0.723169</td>\n",
       "      <td>0.910542</td>\n",
       "      <td>0.933214</td>\n",
       "      <td>0.921738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.621354</td>\n",
       "      <td>0.693703</td>\n",
       "      <td>0.887870</td>\n",
       "      <td>0.931625</td>\n",
       "      <td>0.909221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  threshold       ari       ami         h         c         v\n",
       "0   agglomerative       0.72  0.878614  0.872694  0.979180  0.955741  0.967319\n",
       "1   agglomerative       0.76  0.868667  0.865061  1.000000  0.938823  0.968446\n",
       "2   agglomerative       0.74  0.861964  0.863814  0.989590  0.944990  0.966776\n",
       "3   agglomerative       0.78  0.843574  0.840381  1.000000  0.929737  0.963589\n",
       "4   agglomerative       0.70  0.819750  0.819377  0.946099  0.954265  0.950164\n",
       "5   agglomerative       0.68  0.554317  0.707515  0.868050  0.950357  0.907341\n",
       "6        centroid       0.72  0.861964  0.863814  0.989590  0.944990  0.966776\n",
       "7        centroid       0.75  0.849854  0.846509  0.989590  0.938219  0.963220\n",
       "8        centroid       0.69  0.715355  0.775847  0.917247  0.952894  0.934730\n",
       "9        centroid       0.66  0.559797  0.714185  0.860493  0.957934  0.906603\n",
       "10       centroid       0.63  0.447411  0.597561  0.775449  0.939371  0.849575\n",
       "11       centroid       0.60  0.332870  0.484312  0.689798  0.910247  0.784836\n",
       "12         vector       0.72  0.864654  0.836323  0.977328  0.941743  0.959205\n",
       "13         vector       0.76  0.849854  0.846509  0.989590  0.938219  0.963220\n",
       "14         vector       0.74  0.828405  0.808085  0.977328  0.930745  0.953468\n",
       "15         vector       0.78  0.824889  0.821949  0.989590  0.929050  0.958365\n",
       "16         vector       0.70  0.648380  0.723169  0.910542  0.933214  0.921738\n",
       "17         vector       0.68  0.621354  0.693703  0.887870  0.931625  0.909221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best per method (by ARI):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>ari</th>\n",
       "      <th>ami</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agglomerative</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.878614</td>\n",
       "      <td>0.872694</td>\n",
       "      <td>0.979180</td>\n",
       "      <td>0.955741</td>\n",
       "      <td>0.967319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.861964</td>\n",
       "      <td>0.863814</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.944990</td>\n",
       "      <td>0.966776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.864654</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.941743</td>\n",
       "      <td>0.959205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  threshold       ari       ami         h         c         v\n",
       "0   agglomerative       0.72  0.878614  0.872694  0.979180  0.955741  0.967319\n",
       "6        centroid       0.72  0.861964  0.863814  0.989590  0.944990  0.966776\n",
       "12         vector       0.72  0.864654  0.836323  0.977328  0.941743  0.959205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter sweep for vector/centroid thresholds\n",
    "from itertools import product\n",
    "\n",
    "vector_thresholds = [0.68, 0.70, 0.72, 0.74, 0.76, 0.78]\n",
    "centroid_thresholds = [0.60, 0.63, 0.66, 0.69, 0.72, 0.75]\n",
    "agg_thresholds = [0.68, 0.70, 0.72, 0.74, 0.76, 0.78]\n",
    "\n",
    "results = []\n",
    "true_labels = df_src[\"label\"].tolist() if \"label\" in df_src.columns else None\n",
    "if true_labels is None:\n",
    "    print(\"No labels; skipping sweep.\")\n",
    "else:\n",
    "    true_enc, _ = pd.factorize(pd.Series(true_labels))\n",
    "\n",
    "    # Vector sweeps\n",
    "    for vt in vector_thresholds:\n",
    "        vec_labels = vector_like_cluster(emb, threshold=vt)\n",
    "        pred_enc, _ = pd.factorize(pd.Series(vec_labels))\n",
    "        ari = adjusted_rand_score(true_enc, pred_enc)\n",
    "        ami = adjusted_mutual_info_score(true_enc, pred_enc, average_method=\"arithmetic\")\n",
    "        h, c, v = homogeneity_completeness_v_measure(true_enc, pred_enc)\n",
    "        results.append({\"method\": \"vector\", \"threshold\": vt, \"ari\": ari, \"ami\": ami, \"h\": h, \"c\": c, \"v\": v})\n",
    "\n",
    "    # Centroid sweeps\n",
    "    for ct in centroid_thresholds:\n",
    "        cent_labels = centroid_cluster(emb, threshold=ct)\n",
    "        pred_enc, _ = pd.factorize(pd.Series(cent_labels))\n",
    "        ari = adjusted_rand_score(true_enc, pred_enc)\n",
    "        ami = adjusted_mutual_info_score(true_enc, pred_enc, average_method=\"arithmetic\")\n",
    "        h, c, v = homogeneity_completeness_v_measure(true_enc, pred_enc)\n",
    "        results.append({\"method\": \"centroid\", \"threshold\": ct, \"ari\": ari, \"ami\": ami, \"h\": h, \"c\": c, \"v\": v})\n",
    "\n",
    "    # Agglomerative sweeps\n",
    "    for th in agg_thresholds:\n",
    "        dist_threshold = 1.0 - float(th)\n",
    "        kwargs = dict(n_clusters=None, linkage=\"average\", distance_threshold=dist_threshold)\n",
    "        if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "            kwargs[\"metric\"] = \"cosine\"\n",
    "        else:\n",
    "            kwargs[\"affinity\"] = \"cosine\"\n",
    "        cl = AgglomerativeClustering(**kwargs)\n",
    "        labels = cl.fit_predict(emb)\n",
    "        pred_enc, _ = pd.factorize(pd.Series(labels))\n",
    "        ari = adjusted_rand_score(true_enc, pred_enc)\n",
    "        ami = adjusted_mutual_info_score(true_enc, pred_enc, average_method=\"arithmetic\")\n",
    "        h, c, v = homogeneity_completeness_v_measure(true_enc, pred_enc)\n",
    "        results.append({\"method\": \"agglomerative\", \"threshold\": th, \"ari\": ari, \"ami\": ami, \"h\": h, \"c\": c, \"v\": v})\n",
    "\n",
    "    df_sweep = pd.DataFrame(results).sort_values([\"method\", \"ari\"], ascending=[True, False]).reset_index(drop=True)\n",
    "    display(df_sweep)\n",
    "\n",
    "    # Show best per method\n",
    "    best = df_sweep.sort_values([\"method\", \"ari\"], ascending=[True, False]).groupby(\"method\").head(1)\n",
    "    print(\"Best per method (by ARI):\")\n",
    "    display(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
